{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c414a88e",
   "metadata": {},
   "source": [
    "### Batch processing of iMap records using iNaturalist VisionAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460386f9",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4f9a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import requests\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import math\n",
    "import json\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f5a8b-48e3-4622-90bf-fe67696ee3ed",
   "metadata": {},
   "source": [
    "### Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bbf16c6d-e621-42e2-9304-d60ef83a01b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tmollick\\\\Documents\\\\iMapML\\\\Outputs'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() # Get current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "15e145fc-ce99-4493-a570-7040081e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\tmollick\\Documents\\iMapML\\Outputs\") # Change current working directory\n",
    "# os.listdir() # Check new files in the new directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f766820-7359-4481-9a62-ff645f06554b",
   "metadata": {},
   "source": [
    "### Read the selected iMap presence ID for identification by VisionAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "612c6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1332475, 1332476, 1393477, 1338545, 1248259, 1340080, 1352795, 1352795, 1019292, 1183051, 1183051, 1045374, 1323985, 1324561, 1332475, 1342737, 1344279, 1355565, 1346222, 1348527, 1351159, 1351160, 1351161, 1351361, 1352774, 1355297, 1355661, 1356143, 1391918, 512894, 1249974, 512896, 1352795, 1365813, 1410194, 1410778, 1390011, 1182390, 1391610, 1393455, 1069269, 1165069, 1165071, 1248256, 1271707, 1271710, 1272390, 1272676, 1272681, 1273444, 1283776, 1393478, 1037387, 1045228, 1061881, 1064408, 1078275, 1393542, 1394580, 1395140, 1395141, 1395697, 1407697, 1411932, 1411934, 1412011, 1412340, 1412327, 1413908, 1413910, 1414413, 1413907, 1438087, 1438089, 1438090, 1416694, 1441578, 1443662, 1435543, 1437877, 1439152, 1439282, 1440283, 1440287, 1441455, 1441456, 1442429, 1443498, 1443499, 1443499, 1443499, 1443499, 1444043, 1443662, 1443662, 1443662, 1443662, 1443662, 1443662]\n"
     ]
    }
   ],
   "source": [
    "# Reading the numbers from the text file\n",
    "with open(r\"C:\\Users\\tmollick\\Documents\\iMapML\\Datasets\\presence_ids_with_photos.txt\", \"r\") as file:  # Change the directory to read the presence ids from the text file\n",
    "    presence_ids_with_photos = [int(line.strip()) for line in file]\n",
    "\n",
    "# Print the list to verify\n",
    "print(presence_ids_with_photos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1c5b58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_ids = presence_ids_with_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd94d8",
   "metadata": {},
   "source": [
    "### Accessing iMapInvasives API \n",
    "Create an account using https://www.imapinvasives.org/ address and use the username and password to access the iMap API\n",
    "#### Use your iMap username and password in the code below to get access to the iMap API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4fa0d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to authenticate with: https://imapinvasives.natureserve.org/imap/j_spring_security_check\n",
      "\n",
      "login response: 200\n",
      "\n",
      "Test record access response: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "imap_site = \"imapinvasives\"\n",
    "iMap_username = \"your iMap_username\"   # Replcae with your iMap username\n",
    "iMap_password = \"your iMap_password\"   # Replace with your iMap password\n",
    "\n",
    "login_url = r\"https://{0}.natureserve.org/imap/j_spring_security_check\".format(imap_site)\n",
    "\n",
    "# Attempt to log in\n",
    "print(\"\\nAttempting to authenticate with: {0}\".format(login_url))\n",
    "iMapSession = requests.Session()  # This is a global variable accessed in later functions\n",
    "login_response = iMapSession.post(login_url,{'j_username':iMap_username,'j_password':iMap_password})\n",
    "login_response_message = \"\\nlogin response: {0}\".format(login_response.status_code)\n",
    "print(login_response_message)\n",
    "login_response.raise_for_status()\n",
    "\n",
    "# Attempt to access a record to check if log-in was successful\n",
    "test_aoi_url = r\"https://{0}.natureserve.org/imap/services/aoi/new\".format(imap_site)\n",
    "test_aoi_record = iMapSession.get(test_aoi_url)\n",
    "test_aoi_record_message = \"\\nTest record access response: {0}\".format(test_aoi_record.status_code)\n",
    "print(test_aoi_record_message)\n",
    "\n",
    "if test_aoi_record.status_code == 403:\n",
    "    print(\"\\nResponse Code 403 is most likely the result of an incorrectly entered iMap username or password.  It may also be caused by logging in as a user with insufficient permissions.\")\n",
    "\n",
    "test_aoi_record.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e82470-0d31-44e8-927b-63c197fa05de",
   "metadata": {},
   "source": [
    "### Species Identification using VisionAPI\n",
    "#### This code saves progress incrementally by writing to the Excel file after processing each presence ID. If the script encounters an error or disconnection, it can be resumed without reprocessing the completed records.\n",
    "\n",
    "#### Create an account in RapidAPI using the link https://rapidapi.com and subscribe to iNaturalist VisionAPI. If you don't get the VisionAPI by searching, contact the iNaturalist team. They will create an account for you.\n",
    "\n",
    "### Use your RapidAPI key for the iNaturalist VisionAPI in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0b14ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing presence ID: 1332475\n",
      "\n",
      "Processing presence ID: 1332476\n",
      "\n",
      "Processing presence ID: 1393477\n",
      "\n",
      "Processing presence ID: 1338545\n",
      "\n",
      "Processing presence ID: 1248259\n",
      "\n",
      "Processing presence ID: 1340080\n",
      "\n",
      "Processing presence ID: 1352795\n",
      "Skipping already processed presence ID: 1352795\n",
      "\n",
      "Processing presence ID: 1019292\n",
      "\n",
      "Processing presence ID: 1183051\n",
      "Skipping already processed presence ID: 1183051\n",
      "\n",
      "Processing presence ID: 1045374\n",
      "\n",
      "Processing presence ID: 1323985\n",
      "\n",
      "Processing presence ID: 1324561\n",
      "Skipping already processed presence ID: 1332475\n",
      "\n",
      "Processing presence ID: 1342737\n",
      "\n",
      "Processing presence ID: 1344279\n",
      "\n",
      "Processing presence ID: 1355565\n",
      "\n",
      "Processing presence ID: 1346222\n",
      "\n",
      "Processing presence ID: 1348527\n",
      "\n",
      "Processing presence ID: 1351159\n",
      "\n",
      "Processing presence ID: 1351160\n",
      "\n",
      "Processing presence ID: 1351161\n",
      "\n",
      "Processing presence ID: 1351361\n",
      "\n",
      "Processing presence ID: 1352774\n",
      "\n",
      "Processing presence ID: 1355297\n",
      "\n",
      "Processing presence ID: 1355661\n",
      "\n",
      "Processing presence ID: 1356143\n",
      "\n",
      "Processing presence ID: 1391918\n",
      "\n",
      "Processing presence ID: 512894\n",
      "\n",
      "Processing presence ID: 1249974\n",
      "\n",
      "Processing presence ID: 512896\n",
      "Skipping already processed presence ID: 1352795\n",
      "\n",
      "Processing presence ID: 1365813\n",
      "\n",
      "Processing presence ID: 1410194\n",
      "\n",
      "Processing presence ID: 1410778\n",
      "\n",
      "Processing presence ID: 1390011\n",
      "\n",
      "Processing presence ID: 1182390\n",
      "\n",
      "Processing presence ID: 1391610\n",
      "\n",
      "Processing presence ID: 1393455\n",
      "\n",
      "Processing presence ID: 1069269\n",
      "\n",
      "Processing presence ID: 1165069\n",
      "\n",
      "Processing presence ID: 1165071\n",
      "\n",
      "Processing presence ID: 1248256\n",
      "\n",
      "Processing presence ID: 1271707\n",
      "\n",
      "Processing presence ID: 1271710\n",
      "\n",
      "Processing presence ID: 1272390\n",
      "\n",
      "Processing presence ID: 1272676\n",
      "\n",
      "Processing presence ID: 1272681\n",
      "\n",
      "Processing presence ID: 1273444\n",
      "\n",
      "Processing presence ID: 1283776\n",
      "\n",
      "Processing presence ID: 1393478\n",
      "\n",
      "Processing presence ID: 1037387\n",
      "\n",
      "Processing presence ID: 1045228\n",
      "\n",
      "Processing presence ID: 1061881\n",
      "\n",
      "Processing presence ID: 1064408\n",
      "\n",
      "Processing presence ID: 1078275\n",
      "\n",
      "Processing presence ID: 1393542\n",
      "\n",
      "Processing presence ID: 1394580\n",
      "\n",
      "Processing presence ID: 1395140\n",
      "\n",
      "Processing presence ID: 1395141\n",
      "\n",
      "Processing presence ID: 1395697\n",
      "\n",
      "Processing presence ID: 1407697\n",
      "\n",
      "Processing presence ID: 1411932\n",
      "\n",
      "Processing presence ID: 1411934\n",
      "\n",
      "Processing presence ID: 1412011\n",
      "\n",
      "Processing presence ID: 1412340\n",
      "\n",
      "Processing presence ID: 1412327\n",
      "\n",
      "Processing presence ID: 1413908\n",
      "\n",
      "Processing presence ID: 1413910\n",
      "\n",
      "Processing presence ID: 1414413\n",
      "\n",
      "Processing presence ID: 1413907\n",
      "\n",
      "Processing presence ID: 1438087\n",
      "\n",
      "Processing presence ID: 1438089\n",
      "\n",
      "Processing presence ID: 1438090\n",
      "\n",
      "Processing presence ID: 1416694\n",
      "\n",
      "Processing presence ID: 1441578\n",
      "\n",
      "Processing presence ID: 1443662\n",
      "\n",
      "Processing presence ID: 1435543\n",
      "\n",
      "Processing presence ID: 1437877\n",
      "\n",
      "Processing presence ID: 1439152\n",
      "\n",
      "Processing presence ID: 1439282\n",
      "\n",
      "Processing presence ID: 1440283\n",
      "\n",
      "Processing presence ID: 1440287\n",
      "\n",
      "Processing presence ID: 1441455\n",
      "\n",
      "Processing presence ID: 1441456\n",
      "\n",
      "Processing presence ID: 1442429\n",
      "\n",
      "Processing presence ID: 1443498\n",
      "\n",
      "Processing presence ID: 1443499\n",
      "Skipping already processed presence ID: 1443499\n",
      "Skipping already processed presence ID: 1443499\n",
      "Skipping already processed presence ID: 1443499\n",
      "\n",
      "Processing presence ID: 1444043\n",
      "Skipping already processed presence ID: 1443662\n",
      "Skipping already processed presence ID: 1443662\n",
      "Skipping already processed presence ID: 1443662\n",
      "Skipping already processed presence ID: 1443662\n",
      "Skipping already processed presence ID: 1443662\n",
      "Skipping already processed presence ID: 1443662\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set the path where you will save the output file\n",
    "output_file_path = r\"C:\\Users\\tmollick\\Documents\\iMapML\\Outputs\\Unconfirmed_100_mixed_species.xlsx\" # Change your output path\n",
    "\n",
    "# Function to extract latitude and longitude from the imap_dictionary\n",
    "def get_lat_lon_from_imap(imap_dictionary):\n",
    "    presence_point = imap_dictionary.get(\"presencePoint\")\n",
    "    if presence_point:\n",
    "        return presence_point.get('latitude'), presence_point.get('longitude')\n",
    "\n",
    "    presence_line = imap_dictionary.get(\"presenceLine\")\n",
    "    if presence_line:\n",
    "        return presence_line.get('latitude'), presence_line.get('longitude')\n",
    "\n",
    "    presence_polygon = imap_dictionary.get(\"presencePolygon\")\n",
    "    if presence_polygon:\n",
    "        return presence_polygon.get('latitude'), presence_polygon.get('longitude')\n",
    "\n",
    "    return None, None\n",
    "\n",
    "# Function to reduce the image size in memory\n",
    "def reduce_image_size(image, max_size_kb=700):\n",
    "    exif_data = image.info.get('exif')\n",
    "    quality = 95\n",
    "    while True:\n",
    "        buffer = BytesIO()\n",
    "        if exif_data:\n",
    "            image.save(buffer, \"JPEG\", quality=quality, exif=exif_data)\n",
    "        else:\n",
    "            image.save(buffer, \"JPEG\", quality=quality)\n",
    "        if buffer.tell() <= max_size_kb * 1024 or quality <= 10:\n",
    "            return buffer\n",
    "        quality -= 5\n",
    "\n",
    "# Function to identify species using iNaturalist VisionAPI\n",
    "def identify_species(image_bytes, lat=None, lon=None):\n",
    "    url = \"https://visionapi.p.rapidapi.com/v1/rapidapi/score_image\"\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"Replace with your RapidAPI key for the iNaturalist VisionAPI\",   # Replace with your VisionAPI RapidAPI key   \n",
    "        \"X-RapidAPI-Host\": \"visionapi.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    files = {'image': image_bytes}\n",
    "    data = {}\n",
    "    if lat is not None and lon is not None:\n",
    "        data['lat'] = lat\n",
    "        data['lng'] = lon\n",
    "    \n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to get the image from a URL, handling redirects and setting headers\n",
    "def get_image_from_url(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return Image.open(BytesIO(response.content))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open image. Error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to process and identify species for all presentSpeciesId\n",
    "def process_species_images(imap_dictionary, base_url):\n",
    "    data_rows = []\n",
    "    species_list = imap_dictionary.get(\"speciesList\", [])\n",
    "    \n",
    "    for species in species_list:\n",
    "        photo_url = None\n",
    "        present_species_id = species.get(\"presentSpeciesId\")\n",
    "        presence_id = species.get(\"presenceId\")\n",
    "        imap_sci = species.get(\"nationalSpeciesList\", {}).get(\"scientificName\", \"Unknown\")\n",
    "        imap_com = species.get(\"nationalSpeciesList\", {}).get(\"commonName\", \"Unknown\")\n",
    "        \n",
    "        # Extract imap_record_taxon\n",
    "        imap_record_taxon = species.get(\"nationalSpeciesList\", {}).get(\"inaturalistTaxonId\", \"Unknown\")\n",
    "\n",
    "        # Select only the first photo URL\n",
    "        if \"photos\" in species and species[\"photos\"]:\n",
    "            photo_url = species[\"photos\"][0].get(\"photoUrl\", \"\")\n",
    "        \n",
    "        if photo_url:\n",
    "            img = get_image_from_url(photo_url)\n",
    "            if img:\n",
    "                resized_image_buffer = reduce_image_size(img, max_size_kb=700)\n",
    "                lat, lon = get_lat_lon_from_imap(imap_dictionary)\n",
    "                resized_image_buffer.seek(0)\n",
    "                result = identify_species(resized_image_buffer, lat, lon)\n",
    "                \n",
    "                if result and \"results\" in result and result[\"results\"]:\n",
    "                    # Select the best result based on combined score\n",
    "                    top_result = max(result[\"results\"], key=lambda x: x[\"original_combined_score\"])\n",
    "                    inat_sci = top_result['taxon']['name']\n",
    "                    inat_com = top_result['taxon'].get('preferred_common_name', 'Unknown').capitalize()\n",
    "                    inat_taxon = top_result['taxon']['id']\n",
    "                    geo_score = round(top_result['original_geo_score'], 2)\n",
    "                    com_score = round(top_result['original_combined_score'], 2)\n",
    "                    inatlink_html = f'=HYPERLINK(\"https://www.inaturalist.org/taxa/{inat_taxon}-{inat_sci.replace(\" \", \"-\")}\", \"View\")'\n",
    "                else:\n",
    "                    inat_sci = \"Unknown\"\n",
    "                    inat_com = \"Unknown\"\n",
    "                    inat_taxon = \"Unknown\"\n",
    "                    geo_score = \"Unknown\"\n",
    "                    com_score = \"Unknown\"\n",
    "                    inatlink_html = \"Unknown\"\n",
    "            else:\n",
    "                photo_url = \"No Photo\"\n",
    "                inat_sci = \"Unknown\"\n",
    "                inat_com = \"Unknown\"\n",
    "                inat_taxon = \"Unknown\"\n",
    "                geo_score = \"Unknown\"\n",
    "                com_score = \"Unknown\"\n",
    "                inatlink_html = \"Unknown\"\n",
    "        else:\n",
    "            photo_url = \"No Photo\"\n",
    "            inat_sci = \"Unknown\"\n",
    "            inat_com = \"Unknown\"\n",
    "            inat_taxon = \"Unknown\"\n",
    "            geo_score = \"Unknown\"\n",
    "            com_score = \"Unknown\"\n",
    "            inatlink_html = \"Unknown\"\n",
    "            \n",
    "        species_label = 1 if str(imap_record_taxon) == str(inat_taxon) else 0\n",
    "        imaplink = f\"https://imapinvasives.natureserve.org/imap/services/page/Presence/{presence_id}.html\"\n",
    "        imaplink_html = f'=HYPERLINK(\"{imaplink}\", \"View\")'\n",
    "        iMapPhoto_html = f'=HYPERLINK(\"{photo_url}\", \"View\")' if photo_url != \"No Photo\" else \"No Photo\"\n",
    "        \n",
    "        row = [None, imaplink_html, presence_id, present_species_id, iMapPhoto_html, imap_sci, imap_com, imap_record_taxon, inatlink_html, inat_sci, inat_com, inat_taxon, geo_score, com_score, \"\", species_label, \"\"]\n",
    "        data_rows.append(row)\n",
    "    \n",
    "    return data_rows\n",
    "\n",
    "# Process all the presence IDs\n",
    "def process_multiple_species_ids(presence_ids):\n",
    "    base_url = \"https://imapinvasives.natureserve.org/imap/services/presence/\"  # Keeping the base URL unchanged for the API\n",
    "    output_file = output_file_path\n",
    "    \n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(output_file):\n",
    "        df_existing = pd.read_excel(output_file)\n",
    "        processed_ids = set(df_existing[\"presenceId\"].dropna().astype(int))\n",
    "    else:\n",
    "        df_existing = pd.DataFrame(columns=[\n",
    "            \"S.L.\", \"imaplink\", \"presenceId\", \"presentSpeciesId\", \"iMapPhoto\", \"imap_sci\",\n",
    "            \"imap_com\", \"imap_record_taxon\", \"inatlink\", \"inat_sci\", \"inat_com\", \"inat_taxon\", \n",
    "            \"geo_score\", \"com_score\", \"visual_model\", \"species_label\", \"com_status\"\n",
    "        ])\n",
    "        processed_ids = set()\n",
    "\n",
    "    for idx, presence_id in enumerate(presence_ids, start=1):\n",
    "        if presence_id in processed_ids:\n",
    "            print(f\"Skipping already processed presence ID: {presence_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing presence ID: {presence_id}\")\n",
    "        full_url = f\"{base_url}{presence_id}\"\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                imap_record = iMapSession.get(full_url)  # Using iMapSession to access the API\n",
    "                \n",
    "                if imap_record.status_code == 200:\n",
    "                    imap_dictionary = imap_record.json()\n",
    "                    data_rows = process_species_images(imap_dictionary, base_url)\n",
    "                    for row in data_rows:\n",
    "                        row[0] = idx  # Insert S.L. as the first column\n",
    "                        df_existing.loc[len(df_existing)] = row\n",
    "                    # Save progress after each record\n",
    "                    df_existing.to_excel(output_file, index=False)\n",
    "                    processed_ids.add(presence_id)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve data for presence ID {presence_id}. Status code: {imap_record.status_code}\")\n",
    "                break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error processing presence ID {presence_id}: {e}. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}. Saving progress and exiting.\")\n",
    "                df_existing.to_excel(output_file, index=False)\n",
    "                return\n",
    "\n",
    "# Example usage: Replace presence_ids with your actual list of IDs\n",
    "process_multiple_species_ids(presence_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48ad84-39c3-425d-bb00-739b3406a3f4",
   "metadata": {},
   "source": [
    "### Apply threshold values to the output file from iNaturalist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9cbe70-53dd-49d6-baf4-c4ecbe50e597",
   "metadata": {},
   "source": [
    "### The invasive species Tier can be accessed through the url https://www.nynhp.org/invasives/species-tiers-table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "185bbfd2-8c8c-42f2-9fe4-1e99e8ddf411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables found: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ecological</th>\n",
       "      <th>Socio-Economic</th>\n",
       "      <th>NYS Part 575</th>\n",
       "      <th>NYS_Tier</th>\n",
       "      <th>APIPP</th>\n",
       "      <th>Capital Region</th>\n",
       "      <th>CRISP</th>\n",
       "      <th>Finger Lakes</th>\n",
       "      <th>Lower Hudson</th>\n",
       "      <th>LIISMA</th>\n",
       "      <th>SLELO</th>\n",
       "      <th>WNY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African clawed frog</td>\n",
       "      <td>Xenopus laevis</td>\n",
       "      <td>AA</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Insignificant Positive</td>\n",
       "      <td>Regulated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African elodea</td>\n",
       "      <td>Lagarosiphon major</td>\n",
       "      <td>AP</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africanized honey bee</td>\n",
       "      <td>Apis mellifera scutellata x A. m. ligustica, A...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>Prohibited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agrilus sp. 9895</td>\n",
       "      <td>Agrilus sp. 9895</td>\n",
       "      <td>TA</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alewife</td>\n",
       "      <td>Alosa pseudoharengus</td>\n",
       "      <td>AA</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Insignificant Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Common Name                                    Scientific Name  \\\n",
       "0    African clawed frog                                     Xenopus laevis   \n",
       "1         African elodea                                 Lagarosiphon major   \n",
       "2  Africanized honey bee  Apis mellifera scutellata x A. m. ligustica, A...   \n",
       "3       Agrilus sp. 9895                                   Agrilus sp. 9895   \n",
       "4                Alewife                               Alosa pseudoharengus   \n",
       "\n",
       "  Type    Ecological          Socio-Economic NYS Part 575 NYS_Tier APIPP  \\\n",
       "0   AA      Moderate  Insignificant Positive    Regulated      NaN   NaN   \n",
       "1   AP          High            Low Negative          NaN       1b   NaN   \n",
       "2   TA  Not assessed            Not assessed   Prohibited      NaN   NaN   \n",
       "3   TA  Not assessed            Not assessed          NaN        M   NaN   \n",
       "4   AA      Moderate  Insignificant Negative          NaN      NaN   NaN   \n",
       "\n",
       "  Capital Region CRISP Finger Lakes Lower Hudson LIISMA SLELO  WNY  \n",
       "0            NaN   NaN          NaN            M    NaN   NaN  NaN  \n",
       "1            NaN   NaN          NaN           1c    NaN   NaN  NaN  \n",
       "2            NaN   NaN          NaN            1    NaN   NaN  NaN  \n",
       "3            NaN   NaN          NaN          NaN    NaN   NaN  NaN  \n",
       "4              2   NaN            4          NaN    NaN   NaN    4  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conda install lxml # Run this command if it creates a problem opening the table\n",
    "\n",
    "# URL of the table\n",
    "url = \"https://www.nynhp.org/invasives/species-tiers-table/\"\n",
    "\n",
    "# Read all tables on the page\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Check how many tables were found\n",
    "print(f\"Total tables found: {len(tables)}\")\n",
    "\n",
    "# View the first table (adjust index if needed)\n",
    "df2 = tables[0]\n",
    "\n",
    "# Replace MultiIndex with only the lower-level column names\n",
    "df2.columns = df2.columns.get_level_values(1)\n",
    "\n",
    "# Rename 'NYS' column to 'NYS_Tier'\n",
    "df2.rename(columns={'NYS': 'NYS_Tier'}, inplace=True)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf87dc-abe5-4d08-8b0c-6cb3d859bd16",
   "metadata": {},
   "source": [
    "### Added thredhold and Geo Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45037b8f-5e04-49c8-8433-806c5992005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values for com_score and geo_score\n",
    "threshold_values = {\n",
    "    \"Litylenchus crenatae mccannii\": 86.69,\n",
    "    \"Rhamnus cathartica\": 81.5,\n",
    "    \"Alliaria petiolata\": 88.91,\n",
    "    \"Adelges tsugae\": 82.85,\n",
    "    \"Japanese Knotweed\": 76.73,\n",
    "    \"Berberis thunbergii\": 90.06,\n",
    "    \"Rosa multiflora\": 74.05,\n",
    "    \"Celastrus orbiculatus\": 65.45,\n",
    "    \"Lythrum salicaria\": 89.08,\n",
    "    \"Lycorma delicatula\": 92.79,\n",
    "    \"Ailanthus altissima\": 87.09\n",
    "}\n",
    "default_threshold = 77.62\n",
    "\n",
    "Geo_score_mean = {\n",
    "    \"Litylenchus crenatae mccannii\": 21.54,\n",
    "    \"Rhamnus cathartica\": 31.47,\n",
    "    \"Alliaria petiolata\": 39.89,\n",
    "    \"Adelges tsugae\": 21.26,\n",
    "    \"Reynoutria japonica\": 31.94,\n",
    "    \"Berberis thunbergii\": 36.55,\n",
    "    \"Rosa multiflora\": 41.31,\n",
    "    \"Celastrus orbiculatus\": 33.65,\n",
    "    \"Lythrum salicaria\": 38.21,\n",
    "    \"Lycorma delicatula\": 72.02,\n",
    "    \"Ailanthus altissima\": 32.68\n",
    "}\n",
    "default_geo_score = 36.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef628d21-19a4-4651-8dd4-ffb6eb021dc9",
   "metadata": {},
   "source": [
    "### Generate the final output by applying threshold combined score and mean geo score as well as the NYS invasive species Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ea409711-cc35-4b66-b030-3ab8259e1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. File saved at: Unconfirmed_100_mixes_reports_final.xlsx with hyperlinks preserved and tier-specific geo_score applied.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "input_file = \"Unconfirmed_100_mixed_species.xlsx\"         # Replace with your desired input file here\n",
    "output_file = \"Unconfirmed_100_mixes_reports_final.xlsx\"  # Rename the output file to save to your location\n",
    "\n",
    "# Load the original Excel file using OpenPyXL and Pandas\n",
    "wb = load_workbook(input_file, data_only=False)\n",
    "ws = wb.active\n",
    "df = pd.read_excel(input_file, engine=\"openpyxl\")\n",
    "\n",
    "\n",
    "# Convert columns to numeric where necessary\n",
    "df[\"com_score\"] = pd.to_numeric(df[\"com_score\"], errors=\"coerce\")\n",
    "df[\"geo_score\"] = pd.to_numeric(df[\"geo_score\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# Merge df with df2 to get the NYS_Tier info\n",
    "df = df.merge(df2[['Scientific Name', 'NYS_Tier']], how='left', left_on='imap_sci', right_on='Scientific Name')\n",
    "\n",
    "# Assign thresholds\n",
    "df[\"Species_selected_threshold\"] = df[\"imap_sci\"].apply(lambda x: threshold_values.get(x, default_threshold))\n",
    "df[\"Geo_score_mean\"] = df[\"imap_sci\"].apply(lambda x: Geo_score_mean.get(x, default_geo_score))\n",
    "\n",
    "# Check com_score status (applies to everyone)\n",
    "df[\"Com_score_above_or_below\"] = df.apply(\n",
    "    lambda row: \"Above\" if row[\"com_score\"] >= row[\"Species_selected_threshold\"] else \"Below\", axis=1\n",
    ")\n",
    "\n",
    "# Check geo_score status\n",
    "df[\"Geo_score_above_or_below\"] = df.apply(\n",
    "    lambda row: \"Above\" if row[\"geo_score\"] >= row[\"Geo_score_mean\"] else \"Below\", axis=1\n",
    ")\n",
    "\n",
    "# Apply exception rule based on 'species_label'\n",
    "df[\"com_status\"] = df[\"species_label\"].apply(lambda x: \"Match\" if x == 1 else \"Unmatch\")\n",
    "\n",
    "# Default value for Recommended_status\n",
    "df[\"Recommended_status\"] = \"Manual review\"\n",
    "\n",
    "# Clean up NYS_Tier values (no conversion to numeric because there are non-numeric tiers like 1a, 1b, etc.)\n",
    "df[\"NYS_Tier\"] = df[\"NYS_Tier\"].astype(str).str.strip()\n",
    "\n",
    "# Define the tiers where geo_score applies\n",
    "tiers_with_geo_score = ['1a', '1b', '1c', '1', '2', '3']\n",
    "\n",
    "# Condition for Tiers 1a, 1b, 1c, 1, 2, 3 -> apply com_score + geo_score + match\n",
    "tier_1_to_3_condition = (\n",
    "    (df[\"NYS_Tier\"].isin(tiers_with_geo_score)) &\n",
    "    (df[\"com_score\"] >= df[\"Species_selected_threshold\"]) &\n",
    "    (df[\"geo_score\"] >= df[\"Geo_score_mean\"]) &\n",
    "    (df[\"com_status\"] == \"Match\")\n",
    ")\n",
    "\n",
    "# Condition for Tier 4 and blanks -> apply com_score + match only\n",
    "tier_4_or_blank_condition = (\n",
    "    (~df[\"NYS_Tier\"].isin(tiers_with_geo_score)) &\n",
    "    (df[\"com_score\"] >= df[\"Species_selected_threshold\"]) &\n",
    "    (df[\"com_status\"] == \"Match\")\n",
    ")\n",
    "\n",
    "# Apply conditions\n",
    "df.loc[tier_1_to_3_condition | tier_4_or_blank_condition, \"Recommended_status\"] = \"Automatically confirmed\"\n",
    "\n",
    "# Drop 'Scientific Name' and any other unnecessary columns before export\n",
    "df.drop(columns=[\"Scientific Name\", \"visual_model\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Preserve hyperlinks using `values_only=False`\n",
    "hyperlink_columns = [\"imaplink\", \"iMapPhoto\", \"inatlink\"]\n",
    "\n",
    "# Create a new workbook for writing\n",
    "wb_new = Workbook()\n",
    "ws_new = wb_new.active\n",
    "ws_new.title = \"Processed Data\"\n",
    "\n",
    "# Copy headers (Include both original and new columns)\n",
    "headers = list(df.columns)\n",
    "ws_new.append(headers)\n",
    "\n",
    "# Loop through rows and copy data while preserving hyperlinks\n",
    "for row_idx, row in enumerate(ws.iter_rows(values_only=False), start=1):\n",
    "    if row_idx == 1:  # Skip header row (already written)\n",
    "        continue\n",
    "\n",
    "    new_row = []\n",
    "    row_data = {}\n",
    "\n",
    "    for col_idx, cell in enumerate(row, start=1):\n",
    "        column_name = ws.cell(row=1, column=col_idx).value\n",
    "\n",
    "        # Skip columns we dropped earlier\n",
    "        if column_name in [\"Scientific Name\", \"visual_model\"]:\n",
    "            continue\n",
    "\n",
    "        if cell.hyperlink:\n",
    "            new_cell = ws_new.cell(row=row_idx, column=col_idx)\n",
    "            new_cell.value = cell.value\n",
    "            new_cell.hyperlink = cell.hyperlink.target\n",
    "            new_cell.style = \"Hyperlink\"\n",
    "        else:\n",
    "            row_data[column_name] = cell.value\n",
    "\n",
    "    # Add the data from Pandas DataFrame\n",
    "    for col_name in [\n",
    "        \"Species_selected_threshold\", \"Com_score_above_or_below\", \"Geo_score_mean\",\n",
    "        \"Geo_score_above_or_below\", \"Recommended_status\", \"com_status\", \"NYS_Tier\"\n",
    "    ]:\n",
    "        row_data[col_name] = df.at[row_idx - 2, col_name]\n",
    "\n",
    "    # Ensure the new row is in the correct order (excluding dropped columns)\n",
    "    new_row = [row_data.get(col, None) for col in headers]\n",
    "\n",
    "    ws_new.append(new_row)\n",
    "\n",
    "# Save the final workbook\n",
    "wb_new.save(output_file)\n",
    "\n",
    "print(f\"Processing complete. File saved at: {output_file} with hyperlinks preserved and tier-specific geo_score applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233208d-c738-460b-b53b-fb53a4426a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iMapInvasives)",
   "language": "python",
   "name": "imapinvasives"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
